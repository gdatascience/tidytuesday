---
title: "TidyTemplate"
date: 2023-08-17
output: html_document
---

# TidyTuesday

Join the R4DS Online Learning Community in the weekly #TidyTuesday event!
Every week we post a raw dataset, a chart or article related to that dataset, and ask you to explore the data.
While the dataset will be “tamed”, it will not always be tidy! As such you might need to apply various R for Data Science techniques to wrangle the data into a true tidy format.
The goal of TidyTuesday is to apply your R skills, get feedback, explore other’s work, and connect with the greater #RStats community!
As such we encourage everyone of all skills to participate!

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidytuesdayR)
library(scales)
library(camcorder)
library(ggtext)
library(showtext)
library(tidytext)

# Font selected from http://fonts.google.com
tt_family <- "patua"
font_add_google("Patua One", tt_family)

theme_set(theme_light(base_size = 32))

font_add(family = "fa-brands", regular = "~/Library/Fonts/Font Awesome 6 Brands-Regular-400.otf")
font_add(family = "fa-solid", regular = "~/Library/Fonts/Font Awesome 6 Free-Solid-900.otf")
showtext_auto()

# Colors selected using https://coolors.co/
tt_source <- "{kernlab} package"
bg_color <- "#090D5A"
txt_color <- "#EEEEFF"
yellow <- "#EADF2A"  
pink <- "#E8998D"
light_blue <- "#0472B6"

tt_caption <- paste0("DataViz: Tony Galvan #TidyTuesday<span style='color:", bg_color, ";'>..</span><span style='font-family:fa-solid;color:", txt_color, ";'>&#xf0ce;</span><span style='color:", bg_color, ";'>.</span><span style='color:", txt_color, ";'>", tt_source, "</span><span style='color:", bg_color, ";'>..</span><span style='font-family:fa-brands;color:", txt_color, ";'>&#xf099;</span><span style='color:", bg_color, ";'>.</span><span style='color:", txt_color, ";'>@GDataScience1</span><span style='color:", bg_color, ";'>..</span><span style='font-family:fa-brands;color:", txt_color, ";'>&#xf09b;</span><span style='color:", bg_color, ";'>.</span><span style='color:", txt_color, ";'>GDataScience</span><span style='color:", bg_color, ";'>..</span>")

```

# Load the weekly Data

Download the weekly data and make available in the `tt` object.

```{r Load}

tt <- tt_load("2023-08-15")

```


# Readme

Take a look at the readme for the weekly data to get insight on the dataset.
This includes a data dictionary, source, and a link to an article on the data.

```{r Readme, eval = interactive()}

tt

```


# Glimpse Data

Take an initial look at the format of the data available.

```{r Glimpse}

tt %>% 
  map(glimpse)

```

# Wrangle

Explore the data and process it into a nice format for plotting! Access each dataset by name by using a dollarsign after the `tt` object and then the name of the data set.

```{r Wrangle}

library(kernlab)

data(spam)

spam <- spam |>
  janitor::clean_names()

```


# Start recording

Use the {camcorder} package to record all plots that are output to the console

```{r camcorder}

# start recording
gg_record(
  dir = "~/Downloads/camcorder/2023_08_15_tidy_tuesday_spam", # where to save the recording
  device = "png", # device to use to save images
  width = 6, # width of saved image
  height = 6, # height of saved image
  units = "in", # units for width and height
  dpi = 300 # dpi to use when saving image
)

```

# Theme

Set up a custom data visualization theme

```{r VizTheme}

tt_theme <- function() {
  theme(
    panel.grid = element_blank(),
    axis.ticks = element_blank(),
    panel.border = element_blank(),
    plot.background = element_rect(fill = bg_color),
    panel.background = element_rect(fill = bg_color),
    legend.background = element_rect(fill = bg_color),
    legend.key = element_rect(fill = bg_color),
    strip.background = element_rect(fill = bg_color), 
    plot.title = element_textbox_simple(
      family = tt_family, 
      color = yellow,
      face = "bold",
      size = 450,
      margin = margin(t = 0, r = 0, b = 0, l = 0)
    ),
    plot.title.position = "plot",
    plot.subtitle = element_textbox_simple(
      family = tt_family, 
      color = txt_color,
      size = 68,
      lineheight = 0.3,
      margin = margin(t = 0, r = 0, b = 4, l = 0)
    ),
    plot.caption = element_textbox_simple(
      family = tt_family, 
      color = txt_color,
      size = 28,
      margin = margin(t = 10, r = 0, b = 0, l = 0)
    ),
    plot.caption.position = "plot",
    strip.text = element_text(
      family = tt_family,
      color = txt_color,
      face = "bold",
      size = 36, 
      lineheight = 0.3,
      margin = margin(t = 0, r = 0, b = 0, l = 0)
    ),
    legend.text = element_text(
      family = tt_family,
      color = txt_color,
      size = 32
    ),
    legend.title = element_text(
      family = tt_family,
      color = txt_color,
      size = 32
    ),
    axis.title = element_text(
      family = tt_family,
      color = txt_color,
      size = 32
    ),
    axis.text = element_text(
      family = tt_family,
      color = txt_color,
      size = 32
    ),
  )
}

```


# Visualize

Using your processed dataset, create your unique visualization.

```{r VisualizeClass}

spam |>
  mutate(type = str_to_upper(type)) |>
  count(type) |>
  ggplot(aes(n, type, fill = type)) +
  geom_col(show.legend = FALSE) +
  geom_text(
    aes(label = n),
    color = txt_color,
    family = tt_family,
    size = 32,
    hjust = 1,
    nudge_x = -50
  ) +
  scale_fill_manual(values = c(light_blue, pink)) +
  tt_theme() +
  theme(axis.text.y = element_text(
      family = tt_family,
      color = txt_color,
      size = 64,
      margin = margin(t = 0, r = 0, b = 0, l = 0))) +
  labs(x = "# of emails",
       y = "",
       title = "SPAM",
       subtitle = "Breakdown of emails in the data set",
       caption = tt_caption)
  
```


```{r CorrelationMatrix}

library(ggcorrplot)

spam |>
  select(-type) |>
  cor() |>
  ggcorrplot(
    hc.order = TRUE, 
    type = "upper",
    outline.col = "white",
    ggtheme = tt_theme,
    colors = c(light_blue, txt_color, pink)
  ) +
  labs(
    title = "SPAM",
    subtitle = "How are the variables correlated?",
    caption = tt_caption
  )

```


```{r BoxPlots}

gg_resize_film(
  height = 12, 
  width = 24,
  units = "in",
  dpi = 300
)

spam |>
  pivot_longer(
    cols = 1:57, 
    names_to = "stat", 
    values_to = "value"
  ) |>
  ggplot(aes(type, value, fill = type, color = type)) +
  geom_boxplot(alpha = 0.4, show.legend = FALSE) +
  scale_y_log10() +
  facet_wrap(~stat, scales = "free_y") +
  tt_theme() +
  theme(axis.text.x = element_text(angle = 315)) +
  labs(
    x = NULL,
    y = NULL,
    title = "SPAM",
    subtitle = "How are the variables correlated?",
    caption = tt_caption
  )

```


# Modeling

Based on Julia Silge's blog post - https://juliasilge.com/blog/xgboost-tune-volleyball/

We can start by loading the tidymodels metapackage, and splitting our data into training and testing sets.

```{r SplitData}

library(tidymodels)

set.seed(123)
spam_split <- initial_split(spam, strata = type)
spam_train <- training(spam_split)
spam_test <- testing(spam_split)

```

Since XGBoost is a tree based model, we do not need to do much preprocessing for our data (changing factors to strings, centering, or scaling). 

First we will up our model specification (where we specify which hyperparameters we will tune).

```{r XGBoostSpec}

xgb_spec <- boost_tree(
  trees = 1000,
  tree_depth = tune(), min_n = tune(),
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(), mtry = tune(),         ## randomness
  learn_rate = tune()                          ## step size
) |>
  set_engine("xgboost") %>%
  set_mode("classification")

xgb_spec

```

Next, we will set up a parameter tuning grid using a space-filling design so we can cover the hyperparameter space well

```{r TuningGrid}

xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), spam_train), #depends on the number of predictors
  learn_rate(),
  size = 30
)

xgb_grid

```

Next, we will put the model specification into a workflow using add_formula() as our data preprocessor (instead of a recipe - since we do not have any complicated preprocessing).

```{r XGBoostWorkflow}

xgb_wf <- workflow() |>
  add_formula(type ~ .) |>
  add_model(xgb_spec)

xgb_wf

```

Next, we will create cross-validation resamples that we will use to tune our model

```{r CVResamples}

set.seed(123)
spam_folds <- vfold_cv(spam_train, strata = type)

spam_folds

```

Now, we will tune using the `tune_grid()` function with our tuneable workflow, the cross-validation resamples, and our tuning grid.

```{r XGBoostTune}

doParallel::registerDoParallel()

set.seed(234)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = spam_folds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE)
)

xgb_res

```

With the tuning done, we can explore the results

```{r TuneResults}

gg_resize_film(
  height = 6, 
  width = 6,
  units = "in",
  dpi = 300
)

xgb_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  tt_theme() +
  labs(
    x = NULL, 
    y = "AUC",
    title = "SPAM",
    subtitle = "Which hyperparameter values are best?",
    caption = tt_caption
  )

```

Now, we can choose the best performing set of hyperparameters

```{r SelectBest}

best_auc <- select_best(xgb_res, "roc_auc")
best_auc

```

Finally, we can finalize our tuneable workflow with the best performing set of hyperparameters

```{r FinalizeWF}

final_xgb <- finalize_workflow(
  xgb_wf,
  best_auc
)

final_xgb

```

# Interpret Results

```{r VariableImportance}

library(vip)

final_xgb |>
  fit(data = spam_train) |>
  extract_fit_parsnip() |>
  vi() |>
  top_n(10, wt = Importance) |>
  mutate(
    Variable = case_when(
      Variable == "char_exclamation" ~ 'Contains a "!" symbol',
      Variable == "char_dollar" ~ 'Contains a "$" symbol',
      Variable == "capital_ave" ~ "Avg. length of ALL CAPS words",
      Variable == "capital_long" ~ "Longest ALL CAPS word",
      TRUE ~ paste0('Contains the word "', Variable, '"')
    ),
    Variable = fct_reorder(Variable, Importance)
  ) |>
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col(fill = pink) +
  tt_theme() +
  theme(axis.text.y = element_text(
      family = tt_family,
      color = txt_color,
      size = 36,
      margin = margin(t = 0, r = 0, b = 0, l = 0))) +
  labs(
    y = NULL,
    title = "SPAM",
    subtitle = "What are the most important predictors in determining if an email is spam?",
    caption = tt_caption
  )

```

Now we will use last_fit() to fit our model one last time on the training data and evaluate our model one last time on the testing set.

```{r Eval}

final_res <- last_fit(final_xgb, spam_split)

collect_metrics(final_res)

final_res |>
  collect_predictions() |>
  roc_curve(type, .pred_nonspam) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(
    linewidth = 1.5, 
    color = yellow
  ) +
  geom_abline(
    lty = 2, 
    alpha = 0.5,
    color = pink,
    linewidth = 1.5
  ) +
  tt_theme() +
  labs(
    title = "SPAM",
    subtitle = "ROC Curve",
    caption = tt_caption
  )

```



# Save Image

Save your image for sharing. Be sure to use the `#TidyTuesday` hashtag in your post on twitter! 

```{r}

# This will save your most recent plot
ggsave(
  filename = "2023_08_15_tidy_tuesday_spam.png",
  device = "png")

gg_stop_recording()

gg_playback(
  name = "2023_08_15_tidy_tuesday_spam.gif",
  first_image_duration = 4,
  last_image_duration = 20,
  frame_duration = 0.5
)

```
